{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Labrary"
      ],
      "metadata": {
        "id": "oXLIYZqEuzPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPNUBqNhM_pN",
        "outputId": "76583ffd-65e7-4a43-b28d-1f55c73af8ae"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-23 18:47:50--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2023-08-23 18:47:50--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               Installing PySpark 3.2.3 and Spark NLP 5.0.2\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.0.2\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-23 18:47:50 (115 MB/s) - written to stdout [1191/1191]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "mZ4b92jtvB61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Useful Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "metadata": {
        "id": "FfRApzRANd27"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Spark NLP to read dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "6NLc52AyvJ8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Starting Sparknlp\n",
        "spark= sparknlp.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCG52ZB6No7l",
        "outputId": "007fe8ef-9c16-44cb-95aa-2d360deb58c0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SparkNLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Pyspark version: {}\".format(spark.version))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSRbc6tgOml8",
        "outputId": "ce5eb5f0-c895-42df-beec-d5e08bfe8aad"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkNLP version: 5.0.2\n",
            "Pyspark version: 3.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About Dataset\n",
        "Context:\n",
        "The file contains over 11,000 tweets associated with disaster keywords like “crash”, “quarantine”, and “bush fires” as well as the location and keyword itself. The data structure was inherited from Disasters on social media\n",
        "\n",
        "The tweets were collected on Jan 14th, 2020.\n",
        "\n",
        "Some of the topics people were tweeting:\n",
        "1. The eruption of Taal Volcano in Batangas, Philippines\n",
        "2. Coronavirus\n",
        "3. Bushfires in Australia\n",
        "4. Iran downing of the airplane flight PS752\n",
        "\n",
        "Disclaimer: The dataset contains text that may be considered profane, vulgar, or offensive.\n",
        "\n",
        "Dataset Link:\n",
        "https://www.kaggle.com/datasets/vstepanenko/disaster-tweets"
      ],
      "metadata": {
        "id": "_QRjyOUxzO-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the combined dataset\n",
        "df_combined = spark.read\\\n",
        "    .option(\"header\", True)\\\n",
        "    .option(\"quote\", \"\\\"\")\\\n",
        "    .option(\"escape\", \"\\\"\")\\\n",
        "    .csv(\"tweets.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lmXKvHEIOxsc"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NJce-TsR2Jz",
        "outputId": "0b2fdfa5-1e83-4ae6-f08f-abe64aed6983"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id |keyword|location       |text                                                                                                                                        |target|\n",
            "+---+-------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|0  |ablaze |null           |Communal violence in Bhainsa, Telangana. \"Stones were pelted on Muslims' houses and some houses and vehicles were set ablaze…               |1     |\n",
            "|1  |ablaze |null           |Telangana: Section 144 has been imposed in Bhainsa from January 13 to 15, after clash erupted between two groups on January 12. Po…         |1     |\n",
            "|2  |ablaze |New York City  |Arsonist sets cars ablaze at dealership https://t.co/gOQvyJbpVI                                                                             |1     |\n",
            "|3  |ablaze |Morgantown, WV |Arsonist sets cars ablaze at dealership https://t.co/0gL7NUCPlb https://t.co/u1CcBhOWh9                                                     |1     |\n",
            "|4  |ablaze |null           |\"Lord Jesus, your love brings freedom and pardon. Fill me with your Holy Spirit and set my heart ablaze with your l… https://t.co/VlTznnPNi8|0     |\n",
            "|5  |ablaze |OC             |If this child was Chinese, this tweet would have gone viral. Social media would be ablaze. SNL would have made a racist j…                  |0     |\n",
            "|6  |ablaze |London, England|Several houses have been set ablaze in Ngemsibaa village, Oku sub division in the North West Region of Cameroon by… https://t.co/99uHGAzxy2 |1     |\n",
            "|7  |ablaze |Bharat         |Asansol: A BJP office in Salanpur village was set ablaze last night. BJP has alleged that TMC is behind the incident. Police has b…         |1     |\n",
            "|8  |ablaze |Accra, Ghana   |National Security Minister, Kan Dapaah's side chic has set the internet ablaze with her latest powerful video.… https://t.co/rhzOMQVSlj     |0     |\n",
            "|9  |ablaze |Searching      |This creature who’s soul is no longer clarent but blue ablaze This thing Carrying memories Memories of… https://t.co/tBKSNDrDoX             |0     |\n",
            "+---+-------+---------------+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the \"keyword\" and \"location\" columns"
      ],
      "metadata": {
        "id": "GZ2y5siG1aZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_col= [\"keyword\", \"location\"]\n",
        "df_combined= df_combined.drop(*drop_col)\n",
        "df_combined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsVPNTsqhImP",
        "outputId": "084808c1-a5dc-4899-f43b-3b3754795ed6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+------+\n",
            "| id|                text|target|\n",
            "+---+--------------------+------+\n",
            "|  0|Communal violence...|     1|\n",
            "|  1|Telangana: Sectio...|     1|\n",
            "|  2|Arsonist sets car...|     1|\n",
            "|  3|Arsonist sets car...|     1|\n",
            "|  4|\"Lord Jesus, your...|     0|\n",
            "|  5|If this child was...|     0|\n",
            "|  6|Several houses ha...|     1|\n",
            "|  7|Asansol: A BJP of...|     1|\n",
            "|  8|National Security...|     0|\n",
            "|  9|This creature who...|     0|\n",
            "| 10|Images showing th...|     1|\n",
            "| 11|Social media went...|     0|\n",
            "| 12|Hausa youths set ...|     1|\n",
            "| 13|Under #MamataBane...|     1|\n",
            "| 14|AMEN! Set the who...|     0|\n",
            "| 15|Images showing th...|     1|\n",
            "| 16|No cows today but...|     1|\n",
            "| 17|Rengoku sets my h...|     0|\n",
            "| 18|paulzizkaphoto: “...|     0|\n",
            "| 19|French cameroun s...|     1|\n",
            "+---+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data include some null values. I will drop them."
      ],
      "metadata": {
        "id": "Q0YJveBh1qpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined.groupby(\"target\")\\\n",
        "    .count()\\\n",
        "    .orderBy(col(\"count\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXM59s4uhAdI",
        "outputId": "e08afe5d-9808-46b1-d68f-937b64b97804"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|target|count|\n",
            "+------+-----+\n",
            "|  null|   13|\n",
            "|     1| 2113|\n",
            "|     0| 9251|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping rows with null values in the \"target\" column\n",
        "df_combined = df_combined.na.drop(subset=[\"target\"])\n",
        "\n",
        "# Show the DataFrame after dropping null values\n",
        "df_combined.groupby(\"target\")\\\n",
        "    .count()\\\n",
        "    .orderBy(col(\"count\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNapb0bNiXhh",
        "outputId": "76f5e039-bb9f-43c6-8d17-ce786a1e6141"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|target|count|\n",
            "+------+-----+\n",
            "|     1| 2113|\n",
            "|     0| 9251|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data\n",
        "we're using the sample function with the parameters withReplacement=False, fraction=0.8, and seed=123 to create the train_data DataFrame, which will contain approximately 80% of the data for training. Then, we're using the subtract function to create the test_data DataFrame, which will contain the remaining data for testing."
      ],
      "metadata": {
        "id": "n0kQgOpCgRuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df_combined.sample(False, 0.8, seed=123)  # 80% for training\n",
        "test_data = df_combined.subtract(train_data)  # Remaining data for testing\n"
      ],
      "metadata": {
        "id": "hz432us4fASA"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show(5, truncate=False)\n",
        "test_data.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7I_So8vPPNj",
        "outputId": "26805366-2dcd-4f7a-8126-f7c109c998d9"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id |text                                                                                                                                        |target|\n",
            "+---+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|0  |Communal violence in Bhainsa, Telangana. \"Stones were pelted on Muslims' houses and some houses and vehicles were set ablaze…               |1     |\n",
            "|1  |Telangana: Section 144 has been imposed in Bhainsa from January 13 to 15, after clash erupted between two groups on January 12. Po…         |1     |\n",
            "|3  |Arsonist sets cars ablaze at dealership https://t.co/0gL7NUCPlb https://t.co/u1CcBhOWh9                                                     |1     |\n",
            "|4  |\"Lord Jesus, your love brings freedom and pardon. Fill me with your Holy Spirit and set my heart ablaze with your l… https://t.co/VlTznnPNi8|0     |\n",
            "|5  |If this child was Chinese, this tweet would have gone viral. Social media would be ablaze. SNL would have made a racist j…                  |0     |\n",
            "+---+--------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----+-------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|id  |text                                                                                                                                 |target|\n",
            "+----+-------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|499 |HE HAS A FUCKING HEART AND A LITTLE RAINBOW EMBROIDERED ONTO HIS PANTS IM GOING TO COMMIT ARSON https://t.co/hF30TdQGpy              |0     |\n",
            "|501 |Violence, arson across West Bengal as strikers try to enforce bandh; 55 arrested in Kolkata - Times of India… https://t.co/bIMdUMDstT|1     |\n",
            "|937 |When an eagle soars into the blazing sun, it is not just a show of strength but because he truly belongs at the top. You…            |0     |\n",
            "|2464|“Life naturally involves conflicting interests; people have their own agendas, and they collide with yours. Instead of…              |0     |\n",
            "|2611|That's an unusual sort of collision… https://t.co/WVN2ez9HuD                                                                         |1     |\n",
            "+----+-------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data shape: {}\".format((train_data.count(), len(train_data.columns))))\n",
        "print(\"Test data shape: {}\".format((test_data.count(), len(test_data.columns))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODy3sq1jkFm1",
        "outputId": "bc27b2bb-08cf-4d1b-d65e-fd9a78da209d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (9053, 3)\n",
            "Test data shape: (2311, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark NLP Model Set Up\n",
        "Firstly I will apply SparkNLP DocumentAssembler. DocumentAssembler is a entry point to SparkNLP pipeline.\n",
        "After thar, I will apply Universal Sentence Encoder and then create ClassifierDL.\n",
        "Finally I will put into the pipeline and fit with the train_set."
      ],
      "metadata": {
        "id": "yhKdRzexjILU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **DocumentAssembler:**\n",
        "   The `DocumentAssembler` is used to assemble the input text data into a format suitable for further processing. It's responsible for converting the input text data into a structured document format that can be fed into subsequent NLP components.\n",
        "\n",
        "2. **UniversalSentenceEncoder:**\n",
        "   The `UniversalSentenceEncoder` is a pre-trained sentence embedding model that converts text sentences into dense vector representations (embeddings). These embeddings capture the semantic meaning of the sentences and are useful for downstream tasks like classification.\n",
        "\n",
        "3. **ClassifierDLApproach:**\n",
        "   The `ClassifierDLApproach` is a Deep Learning-based text classification approach. It takes the sentence embeddings generated by the `UniversalSentenceEncoder` and trains a classification model. In this case, the target column, which likely contains the target labels (0, 1), is used as the label column for training.\n",
        "\n",
        "   - `setInputCols([\"sentence_embeddings\"])`: Specifies that the input to the classifier model will be the sentence embeddings generated by the `UniversalSentenceEncoder`.\n",
        "   - `setOutputCol(\"class\")`: Sets the output column name for the classification results.\n",
        "   - `setLabelColumn(\"target\")`: Specifies the column containing the target labels for supervised training.\n",
        "   - `setMaxEpochs(10)`: Sets the maximum number of training epochs.\n",
        "   - `setEnableOutputLogs(True)`: Enables logging of training progress.\n",
        "   - `setLr(0.004)`: Sets the learning rate for training.\n",
        "\n",
        "4. **Pipeline:**\n",
        "   A `Pipeline` is created to define the sequence of stages for processing the data. It includes the `DocumentAssembler`, `UniversalSentenceEncoder`, and `ClassifierDLApproach` stages.\n"
      ],
      "metadata": {
        "id": "PPQ816_QvyDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained()\\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"target\")\\\n",
        "    .setMaxEpochs(10)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setLr(0.004)\\\n",
        "\n",
        "nlpPipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        classsifierdl\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYjVSSA2jDQM",
        "outputId": "564da243-4939-4e22-8835-c00d4d5ef598"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "PYeCD4HzwJ3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting with train_set\n",
        "model = nlpPipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "LNChX-XLkelV"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we fit pipeline, Spark NLP will write the training logs to \"annotator_logs\" folder in our home directory.\n",
        "Here is how you can read the logs:"
      ],
      "metadata": {
        "id": "08ta7Bfqkx91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ~/annotator_logs && ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcNTSiEzk0jV",
        "outputId": "f359fd88-8f07-491e-f1af-0d2a885e6c5c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8\n",
            "-rw-r--r-- 1 root root  789 Aug 23 18:49 ClassifierDLApproach_08885d9bab9e.log\n",
            "-rw-r--r-- 1 root root 3954 Aug 23 18:36 ClassifierDLApproach_319350138664.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For check the result of our model:"
      ],
      "metadata": {
        "id": "HkXLSXJCk2_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/annotator_logs/ClassifierDLApproach_e0b7218e9b57.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W6RcsCEk5U2",
        "outputId": "f12158cc-2b01-49af-bd3e-33acedf8923f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /root/annotator_logs/ClassifierDLApproach_e0b7218e9b57.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the prediction results:"
      ],
      "metadata": {
        "id": "BO11eGoa2LeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds= model.transform(test_data)\n",
        "preds.select(\"target\", \"text\", \"class.result\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noLy_s2Ak_Gm",
        "outputId": "3e48b479-f125-4608-c131-8d0407c95f78"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|target|text                                                                                                                                 |result|\n",
            "+------+-------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|0     |HE HAS A FUCKING HEART AND A LITTLE RAINBOW EMBROIDERED ONTO HIS PANTS IM GOING TO COMMIT ARSON https://t.co/hF30TdQGpy              |[0]   |\n",
            "|1     |Violence, arson across West Bengal as strikers try to enforce bandh; 55 arrested in Kolkata - Times of India… https://t.co/bIMdUMDstT|[0]   |\n",
            "|0     |When an eagle soars into the blazing sun, it is not just a show of strength but because he truly belongs at the top. You…            |[0]   |\n",
            "|0     |“Life naturally involves conflicting interests; people have their own agendas, and they collide with yours. Instead of…              |[0]   |\n",
            "|1     |That's an unusual sort of collision… https://t.co/WVN2ez9HuD                                                                         |[0]   |\n",
            "+------+-------------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pediction Report"
      ],
      "metadata": {
        "id": "X3O82SVOwNw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred= preds.select(\"target\", \"document\", \"class.result\").toPandas()\n",
        "df_pred[\"result\"]= df_pred[\"result\"].apply(lambda x: x[0])\n",
        "print(classification_report(df_pred[\"target\"], df_pred[\"result\"]))\n",
        "print(accuracy_score(df_pred[\"target\"], df_pred[\"result\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9f5Xr26nXZO",
        "outputId": "78ab8d02-c0a3-4bd6-ee03-aeb204465869"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.89      1868\n",
            "           1       0.00      0.00      0.00       443\n",
            "\n",
            "    accuracy                           0.81      2311\n",
            "   macro avg       0.40      0.50      0.45      2311\n",
            "weighted avg       0.65      0.81      0.72      2311\n",
            "\n",
            "0.8083080917351796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}